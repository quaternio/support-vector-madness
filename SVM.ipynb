{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247619da-9dc3-49ed-8be2-8d01b4ad3819",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X, y = make_blobs(n_samples=200, centers=2)\n",
    "idxs_1 = np.argwhere(y==1)\n",
    "idxs_0 = np.argwhere(y==0)\n",
    "X1 = X[np.reshape(idxs_1, idxs_1.size)]\n",
    "X0 = X[np.reshape(idxs_0, idxs_0.size)]\n",
    "\n",
    "plt.plot(X0[:,0], X0[:,1], 'b.', X1[:,0], X1[:,1], 'r.')\n",
    "y[y==0] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68039b-bef9-42fe-893a-68d6ec28c017",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    \"\"\" \n",
    "    A regularized kernel SVM \n",
    "    \n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    C : float\n",
    "        The inverse regularization parameter\n",
    "    kernel: str\n",
    "        The kernel type (e.g. linear, gaussian_rbf, etc..)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    train(X,y):\n",
    "        Trains the model on the dataset (X,y)\n",
    "\n",
    "    predict(q):\n",
    "        Makes a prediction about query point q\n",
    "    \"\"\"\n",
    "    def __init__(self, C, kernel=\"linear\"):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def _compute_w(self, X, y, alpha):\n",
    "        \"\"\" Use representer theorem to retrieve w from alpha \"\"\"\n",
    "        N, D = X.shape\n",
    "\n",
    "        w = np.zeros(D)\n",
    "        for i in range(N):\n",
    "            w += alpha[i]*y[i]*X[i]\n",
    "\n",
    "        return w\n",
    "\n",
    "    def _compute_b(self, y, alpha, K):\n",
    "        N = K.shape[0]\n",
    "\n",
    "        # Pick a point on the margin's boundary\n",
    "        sv_idx = None\n",
    "        for i in range(N):\n",
    "            if alpha[i] > 0:\n",
    "                sv_idx = i\n",
    "        \n",
    "        b = y[sv_idx]\n",
    "        for i in range(N):\n",
    "            b -= alpha[i]*y[i]*K[i,sv_idx]\n",
    "            \n",
    "        return b, sv_idx is not None\n",
    "    \n",
    "    def _float_equals(self, a, b, tol=1e-6):\n",
    "        return abs(a - b) < tol\n",
    "\n",
    "    def _has_converged(self, X, y, alpha, K, eps, j):\n",
    "        \"\"\" Check if alpha values have converged \"\"\"\n",
    "        N, D = X.shape\n",
    "        \n",
    "        w = self._compute_w(X, y, alpha)\n",
    "        b, found = self._compute_b(y, alpha, K)\n",
    "        \n",
    "        if not found:\n",
    "            return False, w, b\n",
    "\n",
    "        converged = True\n",
    "        for i in range(N):\n",
    "            if self._float_equals(alpha[i], 0):\n",
    "                if not y[i]*(w@X[i] + b) >= 1 - eps:\n",
    "                    #print(\"Failure at alpha: \", alpha[i])\n",
    "                    #print(\"with y[i]*(w@X[i] + b) should be >= 1: \", y[i]*(w@X[i] + b))\n",
    "                    converged = False\n",
    "                    break\n",
    "            elif self._float_equals(alpha[i], self.C):\n",
    "                if not y[i]*(w@X[i] + b) <= 1 - eps:\n",
    "                    #print(\"2) Failure at alpha: \", alpha[i])\n",
    "                    #print(\"with y[i]*(w@X[i] + b) should be <= 1: \", y[i]*(w@X[i] + b))\n",
    "                    converged = False\n",
    "                    break\n",
    "            else:\n",
    "                if not self._float_equals((y[i]*(w@X[i] + b)).item(), 1, tol=eps):\n",
    "                    #print(\"3) Failure at alpha: \", alpha[i])\n",
    "                    #print(\"with y[i]*(w@X[i] + b) should be == 1: \", y[i]*(w@X[i] + b))\n",
    "                    converged = False\n",
    "                    break\n",
    "                \n",
    "        return converged, w, b\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        \"\"\" Train the classifier using the SMO algorithm \"\"\"\n",
    "        N, D = X.shape\n",
    "\n",
    "        # Picking feasible alpha\n",
    "        alpha = np.zeros(N)\n",
    "        eps = 0.01\n",
    "        converged = False\n",
    "\n",
    "        # Compute Kernel\n",
    "        if self.kernel == \"gaussian\":\n",
    "            K = self.compute_gaussian_kernel(X)\n",
    "        else:\n",
    "            K = self.compute_linear_kernel(X)\n",
    "\n",
    "        i = 1 # use i (as idx of s) and i-1 (as idx of r) as alpha idxs\n",
    "        while not converged:\n",
    "            masked_alpha = np.copy(alpha)\n",
    "\n",
    "            # Zero out alpha_r and alpha_s to vectorize\n",
    "            masked_alpha[i-1] = 0\n",
    "            masked_alpha[i] = 0\n",
    "            zeta = -masked_alpha@y\n",
    "\n",
    "            # Coefficient a of the quadratic expression in alpha_r\n",
    "            a = -(1/2)*(y[i-1]**2*K[i-1,i-1]+y[i-1]**2*K[i,i]-2*y[i-1]**2*K[i-1,i])\n",
    "\n",
    "            # Coefficient b of the quadratic expression in alpha_r\n",
    "            sum = 0\n",
    "            for j in range(N):\n",
    "                if j == i or j == i-1:\n",
    "                    continue\n",
    "\n",
    "                sum += masked_alpha[j]*y[j]*(K[i,j]-K[i-1,j])\n",
    "                \n",
    "            b = 1-(1/y[i])*y[i-1]+zeta*y[i-1]*(K[i,i]-K[i-1,i])+(1/2)*y[i-1]*sum\n",
    "\n",
    "            endpoint1 = max(0, -y[i-1]*(y[i]*self.C-zeta)) if y[i-1] == y[i] else max(0, y[i-1]*zeta)\n",
    "            endpoint2 = min(self.C, y[i-1]*zeta) if y[i-1] == y[i] else min(self.C, -y[i-1]*(y[i]*self.C-zeta)) \n",
    "            if a != 0:\n",
    "                proposed_alpha_r = max(endpoint1, -b/(2*a), endpoint2)\n",
    "            else:\n",
    "                proposed_alpha_r = max(endpoint1, endpoint2)\n",
    "                \n",
    "            proposed_alpha_s = (1/y[i])*(zeta - y[i-1]*proposed_alpha_r)\n",
    "\n",
    "            # Check if constraints are satisfied\n",
    "            feasible = False\n",
    "            masked_alpha[i-1] = proposed_alpha_r\n",
    "            masked_alpha[i] = proposed_alpha_s\n",
    "            \n",
    "            constraint_a = self._float_equals(masked_alpha@y, 0)\n",
    "            mask = np.logical_and(masked_alpha <= self.C, masked_alpha >= 0)\n",
    "            constraint_b = np.sum(mask.astype(np.int8)) == N\n",
    "\n",
    "            # if y[i-1] == y[i]:\n",
    "            #     if proposed_alpha_r <= min(self.C, y[i-1]*zeta):\n",
    "            #         if proposed_alpha_r >= max(0, -y[i-1]*(y[i]*self.C-zeta)):\n",
    "            #             feasible = True #constraint_a and constraint_b\n",
    "            # else:\n",
    "            #     if proposed_alpha_r <= min(self.C, -y[i-1]*(y[i]*self.C-zeta)):\n",
    "            #         if proposed_alpha_r >= max(0, y[i-1]*zeta):\n",
    "            #             feasible = True #constraint_a and constraint_b\n",
    "\n",
    "            feasible = constraint_a and constraint_b\n",
    "            \n",
    "            if feasible:\n",
    "                alpha[i-1] = proposed_alpha_r\n",
    "                alpha[i] = proposed_alpha_s\n",
    "\n",
    "            if not np.array_equal(alpha, np.zeros_like(alpha)):\n",
    "                converged, w, b = self._has_converged(X, y, alpha, K, eps, i)\n",
    "\n",
    "                if converged:\n",
    "                    self.w = w\n",
    "                    self.b = b\n",
    "            \n",
    "            i += 1\n",
    "            if i >= N:\n",
    "                print(np.linalg.norm(alpha))\n",
    "                i = i % N\n",
    "\n",
    "    def compute_gaussian_kernel(self, X, sigma=1.0):\n",
    "        N, D = X.shape\n",
    "        \n",
    "        K = np.zeros((N,N))\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                K[i,j] = np.exp(-(X[i]-X[j])@(X[i]-X[j])/(2*sigma**2))\n",
    "                \n",
    "        return K\n",
    "\n",
    "    def compute_linear_kernel(self, X):\n",
    "        return X@X.T\n",
    "\n",
    "    def predict(self, q):\n",
    "        return 1 if self.w@q + self.b >= 0 else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da9079-9a4b-4612-ad0c-360d0ff21970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "C = 1\n",
    "\n",
    "svm = SVM(C, kernel=\"linear\")\n",
    "svm.train(X, y.astype('float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d766f-ff27-4762-9ebd-a55afefd4c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X0[:,0], X0[:,1], 'b.', X1[:,0], X1[:,1], 'r.')\n",
    "svm.predict(np.array([-4, 6]))\n",
    "\n",
    "prediction_grid = np.zeros((200, 200))\n",
    "\n",
    "x = np.linspace(-6, 8, 200)\n",
    "y = np.linspace(-1, 12, 200)\n",
    "\n",
    "xv, yv = np.meshgrid(x, y, indexing='xy')\n",
    "for i in range(200):\n",
    "    for j in range(200):\n",
    "        prediction_grid[i,j] = svm.predict(np.array([xv[j,i], yv[j,i]]))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(prediction_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfdc9f-c07c-409d-81b0-c20954255a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
